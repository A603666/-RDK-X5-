#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ°´è´¨æ•°æ®é¢„æµ‹åˆ†æè„šæœ¬
ä½¿ç”¨çœŸå®æ°´è´¨æ•°æ®è¿›è¡ŒLSTMé¢„æµ‹åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
try:
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    from sklearn.linear_model import LinearRegression
    from sklearn.ensemble import RandomForestRegressor
    ML_AVAILABLE = True
    print("âœ“ æœºå™¨å­¦ä¹ åº“åŠ è½½æˆåŠŸ")
except ImportError as e:
    ML_AVAILABLE = False
    print(f"âš ï¸ æœºå™¨å­¦ä¹ åº“æœªå®‰è£…: {e}")
    print("æ­£åœ¨å®‰è£…å¿…è¦çš„åº“...")
    import subprocess
    subprocess.check_call(['pip', 'install', 'scikit-learn', 'matplotlib', 'seaborn'])
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    from sklearn.linear_model import LinearRegression
    from sklearn.ensemble import RandomForestRegressor
    ML_AVAILABLE = True

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class WaterQualityPredictor:
    """æ°´è´¨é¢„æµ‹å™¨"""
    
    def __init__(self, sequence_length=48):
        self.sequence_length = sequence_length  # ä½¿ç”¨48æ¡æ•°æ®é¢„æµ‹ä¸‹48æ¡
        self.scalers = {}
        self.models = {}
        self.history = {}
        
    def load_data(self, csv_file):
        """åŠ è½½æ°´è´¨æ•°æ®"""
        print(f"æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶: {csv_file}")
        df = pd.read_csv(csv_file, encoding='utf-8')
        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"åˆ—å: {df.columns.tolist()}")
        
        # æ˜¾ç¤ºæ–­é¢ä¿¡æ¯
        if 'æ–­é¢åç§°' in df.columns:
            sections = df['æ–­é¢åç§°'].unique()
            print(f"å¯ç”¨æ–­é¢: {sections}")
            return df, sections
        else:
            print("æœªæ‰¾åˆ°æ–­é¢åç§°åˆ—")
            return df, []
    
    def select_section_data(self, df, section_name):
        """é€‰æ‹©ç‰¹å®šæ–­é¢çš„æ•°æ®"""
        if 'æ–­é¢åç§°' not in df.columns:
            print("æ•°æ®ä¸­æ²¡æœ‰æ–­é¢åç§°åˆ—ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®")
            return df
            
        section_data = df[df['æ–­é¢åç§°'] == section_name].copy()
        print(f"æ–­é¢ '{section_name}' çš„æ•°æ®é‡: {len(section_data)}")
        
        if len(section_data) < self.sequence_length * 2:
            print(f"âš ï¸ æ•°æ®é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {self.sequence_length * 2} æ¡æ•°æ®")
            return None
            
        return section_data
    
    def preprocess_data(self, df, target_columns=['æ°´æ¸©', 'pH', 'æº¶è§£æ°§']):
        """æ•°æ®é¢„å¤„ç†"""
        print("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        
        # æ£€æŸ¥ç›®æ ‡åˆ—æ˜¯å¦å­˜åœ¨
        available_columns = []
        for col in target_columns:
            if col in df.columns:
                available_columns.append(col)
            else:
                print(f"âš ï¸ åˆ— '{col}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        if not available_columns:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ç›®æ ‡åˆ—")
            return None, None
            
        print(f"ä½¿ç”¨åˆ—: {available_columns}")
        
        # å¤„ç†æ—¶é—´åˆ—
        if 'ç›‘æµ‹æ—¶é—´' in df.columns:
            df['ç›‘æµ‹æ—¶é—´'] = pd.to_datetime(df['ç›‘æµ‹æ—¶é—´'])
            df = df.sort_values('ç›‘æµ‹æ—¶é—´').reset_index(drop=True)
        
        # æå–æ•°å€¼æ•°æ®å¹¶å¤„ç†ç¼ºå¤±å€¼
        data = df[available_columns].copy()
        
        # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œéæ•°å€¼è½¬ä¸ºNaN
        for col in available_columns:
            data[col] = pd.to_numeric(data[col], errors='coerce')
        
        # æ˜¾ç¤ºç¼ºå¤±å€¼ä¿¡æ¯
        missing_info = data.isnull().sum()
        print("ç¼ºå¤±å€¼ç»Ÿè®¡:")
        for col, missing in missing_info.items():
            if missing > 0:
                print(f"  {col}: {missing} ({missing/len(data)*100:.1f}%)")
        
        # å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨å‰å‘å¡«å……å’Œåå‘å¡«å……ï¼‰
        data = data.fillna(method='ffill').fillna(method='bfill')
        
        # å¦‚æœä»æœ‰ç¼ºå¤±å€¼ï¼Œä½¿ç”¨å‡å€¼å¡«å……
        data = data.fillna(data.mean())
        
        print(f"é¢„å¤„ç†åæ•°æ®å½¢çŠ¶: {data.shape}")
        print("æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
        print(data.describe())
        
        return data, available_columns
    
    def create_sequences(self, data, target_col):
        """åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®"""
        values = data[target_col].values

        X, y = [], []
        # åˆ›å»ºæ»‘åŠ¨çª—å£æ•°æ®
        for i in range(self.sequence_length, len(values)):
            X.append(values[i-self.sequence_length:i])
            y.append(values[i])

        return np.array(X), np.array(y)

    def create_prediction_sequences(self, data, target_col):
        """åˆ›å»ºç”¨äºé¢„æµ‹48ä¸ªæ—¶é—´æ­¥çš„åºåˆ—æ•°æ®"""
        values = data[target_col].values

        X, y = [], []
        # ä½¿ç”¨48ä¸ªå†å²æ•°æ®é¢„æµ‹ä¸‹48ä¸ªæ•°æ®
        for i in range(self.sequence_length, len(values) - self.sequence_length + 1):
            X.append(values[i-self.sequence_length:i])
            y.append(values[i:i+self.sequence_length])

        return np.array(X), np.array(y)

    def build_model(self, model_type='rf'):
        """æ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹"""
        if model_type == 'rf':
            return RandomForestRegressor(n_estimators=100, random_state=42)
        else:
            return LinearRegression()
    
    def train_and_predict(self, data, target_columns):
        """è®­ç»ƒæ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹"""
        results = {}

        for col in target_columns:
            print(f"\n{'='*50}")
            print(f"æ­£åœ¨å¤„ç†å‚æ•°: {col}")
            print(f"{'='*50}")

            # æ•°æ®æ ‡å‡†åŒ–
            scaler = MinMaxScaler()
            scaled_data = scaler.fit_transform(data[[col]])
            self.scalers[col] = scaler

            # åˆ›å»ºåºåˆ—æ•°æ®ç”¨äºé¢„æµ‹48ä¸ªæ—¶é—´æ­¥
            X, y = self.create_prediction_sequences(pd.DataFrame(scaled_data, columns=[col]), col)

            if len(X) == 0:
                print(f"âš ï¸ {col}: æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºåºåˆ—")
                continue

            print(f"åºåˆ—æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")

            # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]

            # ä¸ºäº†ä½¿ç”¨ä¼ ç»ŸMLæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦å°†å¤šè¾“å‡ºé—®é¢˜è½¬æ¢ä¸ºå¤šä¸ªå•è¾“å‡ºé—®é¢˜
            # è¿™é‡Œæˆ‘ä»¬ç®€åŒ–ä¸ºé¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œç„¶åé€’å½’é¢„æµ‹48æ­¥
            X_simple, y_simple = self.create_sequences(pd.DataFrame(scaled_data, columns=[col]), col)

            if len(X_simple) == 0:
                continue

            split_idx_simple = int(len(X_simple) * 0.8)
            X_train_simple = X_simple[:split_idx_simple]
            X_test_simple = X_simple[split_idx_simple:]
            y_train_simple = y_simple[:split_idx_simple]
            y_test_simple = y_simple[split_idx_simple:]

            # æ„å»ºå’Œè®­ç»ƒæ¨¡å‹
            model = self.build_model('rf')

            print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            model.fit(X_train_simple, y_train_simple)

            self.models[col] = model

            # é€’å½’é¢„æµ‹48æ­¥
            y_pred_sequences = []
            for i in range(len(X_test)):
                # ä½¿ç”¨å‰48ä¸ªæ•°æ®ç‚¹é¢„æµ‹å48ä¸ª
                current_sequence = X_test[i].copy()
                predictions = []

                for step in range(self.sequence_length):
                    # é¢„æµ‹ä¸‹ä¸€ä¸ªå€¼
                    next_pred = model.predict([current_sequence])[0]
                    predictions.append(next_pred)

                    # æ›´æ–°åºåˆ—ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
                    current_sequence = np.append(current_sequence[1:], next_pred)

                y_pred_sequences.append(predictions)

            y_pred_sequences = np.array(y_pred_sequences)

            # åæ ‡å‡†åŒ–
            y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(y_test.shape)
            y_pred_orig = scaler.inverse_transform(y_pred_sequences.reshape(-1, 1)).reshape(y_pred_sequences.shape)

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            mse = mean_squared_error(y_test_orig.flatten(), y_pred_orig.flatten())
            mae = mean_absolute_error(y_test_orig.flatten(), y_pred_orig.flatten())
            rmse = np.sqrt(mse)
            r2 = r2_score(y_test_orig.flatten(), y_pred_orig.flatten())

            # è®¡ç®—MAPE
            mape = np.mean(np.abs((y_test_orig.flatten() - y_pred_orig.flatten()) / np.maximum(np.abs(y_test_orig.flatten()), 1e-8))) * 100

            results[col] = {
                'mse': mse,
                'mae': mae,
                'rmse': rmse,
                'r2': r2,
                'mape': mape,
                'y_test': y_test_orig,
                'y_pred': y_pred_orig,
                'model_type': 'Random Forest'
            }

            print(f"\n{col} é¢„æµ‹æ€§èƒ½æŒ‡æ ‡:")
            print(f"  MSE (å‡æ–¹è¯¯å·®): {mse:.4f}")
            print(f"  MAE (å¹³å‡ç»å¯¹è¯¯å·®): {mae:.4f}")
            print(f"  RMSE (å‡æ–¹æ ¹è¯¯å·®): {rmse:.4f}")
            print(f"  RÂ² (å†³å®šç³»æ•°): {r2:.4f}")
            print(f"  MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®): {mape:.2f}%")

        return results
    
    def plot_results(self, results, section_name):
        """ç»˜åˆ¶é¢„æµ‹ç»“æœ"""
        n_params = len(results)
        fig, axes = plt.subplots(n_params, 2, figsize=(15, 5*n_params))
        
        if n_params == 1:
            axes = axes.reshape(1, -1)
        
        for i, (param, result) in enumerate(results.items()):
            # é¢„æµ‹ç»“æœå¯¹æ¯”
            ax1 = axes[i, 0]
            
            # åªæ˜¾ç¤ºå‰5ä¸ªé¢„æµ‹åºåˆ—çš„å¯¹æ¯”
            n_show = min(5, len(result['y_test']))
            for j in range(n_show):
                ax1.plot(result['y_test'][j], label=f'çœŸå®å€¼ {j+1}', alpha=0.7)
                ax1.plot(result['y_pred'][j], label=f'é¢„æµ‹å€¼ {j+1}', linestyle='--', alpha=0.7)
            
            ax1.set_title(f'{section_name} - {param} é¢„æµ‹å¯¹æ¯”')
            ax1.set_xlabel('æ—¶é—´æ­¥')
            ax1.set_ylabel(param)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # è¯¯å·®åˆ†å¸ƒ
            ax2 = axes[i, 1]
            errors = (result['y_test'] - result['y_pred']).flatten()
            ax2.hist(errors, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            ax2.set_title(f'{param} é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
            ax2.set_xlabel('é¢„æµ‹è¯¯å·®')
            ax2.set_ylabel('é¢‘æ¬¡')
            ax2.axvline(0, color='red', linestyle='--', alpha=0.7, label='é›¶è¯¯å·®çº¿')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{section_name}_prediction_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # æ€§èƒ½æŒ‡æ ‡æ±‡æ€»å›¾
        self.plot_performance_summary(results, section_name)
    
    def plot_performance_summary(self, results, section_name):
        """ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡æ±‡æ€»"""
        metrics = ['MSE', 'MAE', 'RMSE', 'RÂ²', 'MAPE(%)']
        params = list(results.keys())
        
        fig, axes = plt.subplots(1, len(metrics), figsize=(20, 4))
        
        for i, metric in enumerate(metrics):
            values = []
            for param in params:
                if metric == 'MAPE(%)':
                    values.append(results[param]['mape'])
                else:
                    values.append(results[param][metric.lower().replace('Â²', '2')])
            
            axes[i].bar(params, values, color=plt.cm.Set3(np.linspace(0, 1, len(params))))
            axes[i].set_title(f'{metric}')
            axes[i].set_ylabel(metric)
            
            # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
            for j, v in enumerate(values):
                axes[i].text(j, v, f'{v:.3f}', ha='center', va='bottom')
        
        plt.suptitle(f'{section_name} - é¢„æµ‹æ€§èƒ½æŒ‡æ ‡æ±‡æ€»', fontsize=16)
        plt.tight_layout()
        plt.savefig(f'{section_name}_performance_summary.png', dpi=300, bbox_inches='tight')
        plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŠ æ°´è´¨æ•°æ®é¢„æµ‹åˆ†æç³»ç»Ÿ")
    print("=" * 50)
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = WaterQualityPredictor(sequence_length=48)
    
    # åŠ è½½æ•°æ®
    df, sections = predictor.load_data('æ°´è´¨æ•°æ®.csv')
    
    if len(sections) == 0:
        print("âŒ æœªæ‰¾åˆ°æ–­é¢ä¿¡æ¯ï¼Œç¨‹åºé€€å‡º")
        return
    
    # é€‰æ‹©æ•°æ®é‡æœ€å¤šçš„æ–­é¢
    section_counts = df['æ–­é¢åç§°'].value_counts()
    print("\næ–­é¢æ•°æ®é‡ç»Ÿè®¡:")
    for section, count in section_counts.head(10).items():
        print(f"  {section}: {count} æ¡")
    
    # é€‰æ‹©æ•°æ®é‡æœ€å¤šçš„æ–­é¢
    selected_section = section_counts.index[0]
    print(f"\né€‰æ‹©æ–­é¢: {selected_section} (æ•°æ®é‡: {section_counts[selected_section]})")
    
    # æå–æ–­é¢æ•°æ®
    section_data = predictor.select_section_data(df, selected_section)
    if section_data is None:
        print("âŒ æ–­é¢æ•°æ®ä¸è¶³ï¼Œç¨‹åºé€€å‡º")
        return
    
    # æ•°æ®é¢„å¤„ç†
    processed_data, target_columns = predictor.preprocess_data(section_data)
    if processed_data is None:
        print("âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # è®­ç»ƒå’Œé¢„æµ‹
    print(f"\nå¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨ {predictor.sequence_length} æ¡æ•°æ®é¢„æµ‹ä¸‹ {predictor.sequence_length} æ¡æ•°æ®")
    results = predictor.train_and_predict(processed_data, target_columns)
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸè®­ç»ƒä»»ä½•æ¨¡å‹")
        return
    
    # æ˜¾ç¤ºç»“æœæ±‡æ€»
    print(f"\n{'='*60}")
    print(f"é¢„æµ‹ç»“æœæ±‡æ€» - æ–­é¢: {selected_section}")
    print(f"{'='*60}")
    
    for param, result in results.items():
        print(f"\nğŸ“Š {param} é¢„æµ‹æ€§èƒ½:")
        print(f"  âœ“ MSE: {result['mse']:.4f}")
        print(f"  âœ“ MAE: {result['mae']:.4f}")
        print(f"  âœ“ RMSE: {result['rmse']:.4f}")
        print(f"  âœ“ RÂ²: {result['r2']:.4f}")
        print(f"  âœ“ MAPE: {result['mape']:.2f}%")
        
        # æ€§èƒ½è¯„ä»·
        if result['r2'] > 0.8:
            print(f"  ğŸ‰ {param} é¢„æµ‹æ•ˆæœä¼˜ç§€!")
        elif result['r2'] > 0.6:
            print(f"  ğŸ‘ {param} é¢„æµ‹æ•ˆæœè‰¯å¥½!")
        elif result['r2'] > 0.4:
            print(f"  âš ï¸ {param} é¢„æµ‹æ•ˆæœä¸€èˆ¬")
        else:
            print(f"  âŒ {param} é¢„æµ‹æ•ˆæœè¾ƒå·®")
    
    # ç»˜åˆ¶ç»“æœ
    predictor.plot_results(results, selected_section)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º:")
    print(f"  ğŸ“ˆ {selected_section}_prediction_results.png")
    print(f"  ğŸ“Š {selected_section}_performance_summary.png")

if __name__ == "__main__":
    main()
